==> searching: bert/embeddings/word_embeddings, found name: bert/embeddings/word_embeddings
2020-01-14 22:07:24.655844: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2020-01-14 22:07:24.659724: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.
==> searching: bert/embeddings/token_type_embeddings, found name: bert/embeddings/token_type_embeddings
==> searching: bert/embeddings/position_embeddings, found name: bert/embeddings/position_embeddings
==> searching: bert/embeddings/LayerNorm/gamma, found name: bert/embeddings/LayerNorm/gamma
==> searching: bert/embeddings/LayerNorm/beta, found name: bert/embeddings/LayerNorm/beta
==> searching: bert/encoder/embedding_hidden_mapping_in/kernel, found name: bert/encoder/embedding_hidden_mapping_in/kernel
==> searching: bert/encoder/embedding_hidden_mapping_in/bias, found name: bert/encoder/embedding_hidden_mapping_in/bias
==> searching: bert/encoder/transformer/group_0/inner_group_0/attention/self/query/kernel, found name: bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel
==> searching: bert/encoder/transformer/group_0/inner_group_0/attention/self/query/bias, found name: bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias
==> searching: bert/encoder/transformer/group_0/inner_group_0/attention/self/key/kernel, found name: bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel
==> searching: bert/encoder/transformer/group_0/inner_group_0/attention/self/key/bias, found name: bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias
==> searching: bert/encoder/transformer/group_0/inner_group_0/attention/self/value/kernel, found name: bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel
==> searching: bert/encoder/transformer/group_0/inner_group_0/attention/self/value/bias, found name: bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias
==> searching: bert/encoder/transformer/group_0/inner_group_0/attention/output/dense/kernel, found name: bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel
==> searching: bert/encoder/transformer/group_0/inner_group_0/attention/output/dense/bias, found name: bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias
==> searching: bert/encoder/transformer/group_0/inner_group_0/attention/output/LayerNorm/gamma, found name: bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma
==> searching: bert/encoder/transformer/group_0/inner_group_0/attention/output/LayerNorm/beta, found name: bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta
==> searching: bert/encoder/transformer/group_0/inner_group_0/intermediate/dense/kernel, found name: bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel
==> searching: bert/encoder/transformer/group_0/inner_group_0/intermediate/dense/bias, found name: bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias
==> searching: bert/encoder/transformer/group_0/inner_group_0/output/dense/kernel, found name: bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel
==> searching: bert/encoder/transformer/group_0/inner_group_0/output/dense/bias, found name: bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias
==> searching: bert/encoder/transformer/group_0/inner_group_0/output/LayerNorm/gamma, found name: bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma
==> searching: bert/encoder/transformer/group_0/inner_group_0/output/LayerNorm/beta, found name: bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta
==> searching: bert/pooler/dense/kernel, found name: bert/pooler/dense/kernel
==> searching: bert/pooler/dense/bias, found name: bert/pooler/dense/bias
Model: "model_2"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
Input-Token (InputLayer)        (None, None)         0
__________________________________________________________________________________________________
Sequence-Mask (ZeroMasking)     (None, None)         0           Input-Token[0][0]
__________________________________________________________________________________________________
Input-Segment (InputLayer)      (None, None)         0
__________________________________________________________________________________________________
Embedding-Token (Embedding)     (None, None, 128)    2704384     Sequence-Mask[0][0]
__________________________________________________________________________________________________
Embedding-Segment (Embedding)   (None, None, 128)    256         Input-Segment[0][0]
__________________________________________________________________________________________________
Embedding-Token-Segment (Add)   (None, None, 128)    0           Embedding-Token[0][0]
                                                                 Embedding-Segment[0][0]
__________________________________________________________________________________________________
Embedding-Position (PositionEmb (None, None, 128)    65536       Embedding-Token-Segment[0][0]
__________________________________________________________________________________________________
Embedding-Norm (LayerNormalizat (None, None, 128)    256         Embedding-Position[0][0]
__________________________________________________________________________________________________
Embedding-Mapping (Dense)       (None, None, 384)    49536       Embedding-Norm[0][0]
__________________________________________________________________________________________________
Encoder-1-MultiHeadSelfAttentio (None, None, 384)    591360      Embedding-Mapping[0][0]
                                                                 Embedding-Mapping[0][0]
                                                                 Embedding-Mapping[0][0]
                                                                 Encoder-1-FeedForward-Norm[0][0]
                                                                 Encoder-1-FeedForward-Norm[0][0]
                                                                 Encoder-1-FeedForward-Norm[0][0]
                                                                 Encoder-1-FeedForward-Norm[1][0]
                                                                 Encoder-1-FeedForward-Norm[1][0]
                                                                 Encoder-1-FeedForward-Norm[1][0]
                                                                 Encoder-1-FeedForward-Norm[2][0]
                                                                 Encoder-1-FeedForward-Norm[2][0]
                                                                 Encoder-1-FeedForward-Norm[2][0]
                                                                 Encoder-1-FeedForward-Norm[3][0]
                                                                 Encoder-1-FeedForward-Norm[3][0]
                                                                 Encoder-1-FeedForward-Norm[3][0]
                                                                 Encoder-1-FeedForward-Norm[4][0]
                                                                 Encoder-1-FeedForward-Norm[4][0]
                                                                 Encoder-1-FeedForward-Norm[4][0]
__________________________________________________________________________________________________
Encoder-1-MultiHeadSelfAttentio (None, None, 384)    0           Embedding-Mapping[0][0]
                                                                 Encoder-1-MultiHeadSelfAttention[
                                                                 Encoder-1-FeedForward-Norm[0][0]
                                                                 Encoder-1-MultiHeadSelfAttention[
                                                                 Encoder-1-FeedForward-Norm[1][0]
                                                                 Encoder-1-MultiHeadSelfAttention[
                                                                 Encoder-1-FeedForward-Norm[2][0]
                                                                 Encoder-1-MultiHeadSelfAttention[
                                                                 Encoder-1-FeedForward-Norm[3][0]
                                                                 Encoder-1-MultiHeadSelfAttention[
                                                                 Encoder-1-FeedForward-Norm[4][0]
                                                                 Encoder-1-MultiHeadSelfAttention[
__________________________________________________________________________________________________
Encoder-1-MultiHeadSelfAttentio (None, None, 384)    768         Encoder-1-MultiHeadSelfAttention-
                                                                 Encoder-1-MultiHeadSelfAttention-
                                                                 Encoder-1-MultiHeadSelfAttention-
                                                                 Encoder-1-MultiHeadSelfAttention-
                                                                 Encoder-1-MultiHeadSelfAttention-
                                                                 Encoder-1-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-1-FeedForward (FeedForw (None, None, 384)    1181568     Encoder-1-MultiHeadSelfAttention-
                                                                 Encoder-1-MultiHeadSelfAttention-
                                                                 Encoder-1-MultiHeadSelfAttention-
                                                                 Encoder-1-MultiHeadSelfAttention-
                                                                 Encoder-1-MultiHeadSelfAttention-
                                                                 Encoder-1-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-1-FeedForward-Add (Add) (None, None, 384)    0           Encoder-1-MultiHeadSelfAttention-
                                                                 Encoder-1-FeedForward[0][0]
                                                                 Encoder-1-MultiHeadSelfAttention-
                                                                 Encoder-1-FeedForward[1][0]
                                                                 Encoder-1-MultiHeadSelfAttention-
                                                                 Encoder-1-FeedForward[2][0]
                                                                 Encoder-1-MultiHeadSelfAttention-
                                                                 Encoder-1-FeedForward[3][0]
                                                                 Encoder-1-MultiHeadSelfAttention-
                                                                 Encoder-1-FeedForward[4][0]
                                                                 Encoder-1-MultiHeadSelfAttention-
                                                                 Encoder-1-FeedForward[5][0]
__________________________________________________________________________________________________
Encoder-1-FeedForward-Norm (Lay (None, None, 384)    768         Encoder-1-FeedForward-Add[0][0]
                                                                 Encoder-1-FeedForward-Add[1][0]
                                                                 Encoder-1-FeedForward-Add[2][0]
                                                                 Encoder-1-FeedForward-Add[3][0]
                                                                 Encoder-1-FeedForward-Add[4][0]
                                                                 Encoder-1-FeedForward-Add[5][0]
__________________________________________________________________________________________________
Pooler (Lambda)                 (None, 384)          0           Encoder-1-FeedForward-Norm[5][0]
__________________________________________________________________________________________________
Pooler-Dense (Dense)            (None, 384)          147840      Pooler[0][0]
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 384)          0           Pooler-Dense[0][0]
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 2)            770         dropout_1[0][0]
==================================================================================================
Total params: 4,743,042
Trainable params: 4,743,042
Non-trainable params: 0
__________________________________________________________________________________________________
WARNING:tensorflow:From /Users/e/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /Users/e/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Epoch 1/10

 1/13 [=>............................] - ETA: 4:46 - loss: 0.8067 - accuracy: 0.2812
 2/13 [===>..........................] - ETA: 3:18 - loss: 0.7881 - accuracy: 0.2969
 3/13 [=====>........................] - ETA: 2:44 - loss: 0.7889 - accuracy: 0.3021
 4/13 [========>.....................] - ETA: 2:20 - loss: 0.7837 - accuracy: 0.3203
 5/13 [==========>...................] - ETA: 2:00 - loss: 0.7872 - accuracy: 0.3000
 6/13 [============>.................] - ETA: 1:42 - loss: 0.7784 - accuracy: 0.3125
 7/13 [===============>..............] - ETA: 1:25 - loss: 0.7754 - accuracy: 0.3170
 8/13 [=================>............] - ETA: 1:10 - loss: 0.7830 - accuracy: 0.3008
 9/13 [===================>..........] - ETA: 55s - loss: 0.7813 - accuracy: 0.3090
10/13 [======================>.......] - ETA: 41s - loss: 0.7764 - accuracy: 0.3156
11/13 [========================>.....] - ETA: 27s - loss: 0.7729 - accuracy: 0.3239
12/13 [==========================>...] - ETA: 13s - loss: 0.7744 - accuracy: 0.3151
13/13 [==============================] - 172s 13s/step - loss: 0.7769 - accuracy: 0.3022
val_acc: 0.35294, best_val_acc: 0.35294, test_acc: 0.29412

Epoch 2/10

 1/13 [=>............................] - ETA: 2:22 - loss: 0.8164 - accuracy: 0.1875
 2/13 [===>..........................] - ETA: 2:17 - loss: 0.8083 - accuracy: 0.2656
 3/13 [=====>........................] - ETA: 2:04 - loss: 0.7854 - accuracy: 0.3229
 4/13 [========>.....................] - ETA: 1:53 - loss: 0.7773 - accuracy: 0.3281
 5/13 [==========>...................] - ETA: 1:40 - loss: 0.7672 - accuracy: 0.3375
 6/13 [============>.................] - ETA: 1:28 - loss: 0.7577 - accuracy: 0.3646
 7/13 [===============>..............] - ETA: 1:15 - loss: 0.7545 - accuracy: 0.3839
 8/13 [=================>............] - ETA: 1:02 - loss: 0.7556 - accuracy: 0.3633
 9/13 [===================>..........] - ETA: 49s - loss: 0.7540 - accuracy: 0.3611
10/13 [======================>.......] - ETA: 37s - loss: 0.7494 - accuracy: 0.3594
11/13 [========================>.....] - ETA: 24s - loss: 0.7460 - accuracy: 0.3665
12/13 [==========================>...] - ETA: 12s - loss: 0.7435 - accuracy: 0.3750
13/13 [==============================] - 157s 12s/step - loss: 0.7417 - accuracy: 0.3735
val_acc: 0.45098, best_val_acc: 0.45098, test_acc: 0.35294

Epoch 3/10

 1/13 [=>............................] - ETA: 2:13 - loss: 0.6835 - accuracy: 0.5312
 2/13 [===>..........................] - ETA: 2:05 - loss: 0.7049 - accuracy: 0.4688
 3/13 [=====>........................] - ETA: 1:55 - loss: 0.7092 - accuracy: 0.4479
 4/13 [========>.....................] - ETA: 1:44 - loss: 0.7063 - accuracy: 0.4609
 5/13 [==========>...................] - ETA: 1:33 - loss: 0.7055 - accuracy: 0.4563
 6/13 [============>.................] - ETA: 1:22 - loss: 0.7055 - accuracy: 0.4635
 7/13 [===============>..............] - ETA: 1:10 - loss: 0.7050 - accuracy: 0.4643
 8/13 [=================>............] - ETA: 58s - loss: 0.6972 - accuracy: 0.4922
 9/13 [===================>..........] - ETA: 46s - loss: 0.6954 - accuracy: 0.5069
10/13 [======================>.......] - ETA: 35s - loss: 0.6951 - accuracy: 0.5063
11/13 [========================>.....] - ETA: 23s - loss: 0.6937 - accuracy: 0.5227
12/13 [==========================>...] - ETA: 11s - loss: 0.6905 - accuracy: 0.5286
13/13 [==============================] - 150s 12s/step - loss: 0.6898 - accuracy: 0.5307
val_acc: 0.68627, best_val_acc: 0.68627, test_acc: 0.62745

Epoch 4/10

 1/13 [=>............................] - ETA: 2:10 - loss: 0.6649 - accuracy: 0.5938
 2/13 [===>..........................] - ETA: 2:04 - loss: 0.6658 - accuracy: 0.6094
 3/13 [=====>........................] - ETA: 1:54 - loss: 0.6697 - accuracy: 0.5938
 4/13 [========>.....................] - ETA: 1:44 - loss: 0.6681 - accuracy: 0.6016
 5/13 [==========>...................] - ETA: 1:32 - loss: 0.6633 - accuracy: 0.6313
 6/13 [============>.................] - ETA: 1:20 - loss: 0.6577 - accuracy: 0.6458
 7/13 [===============>..............] - ETA: 1:09 - loss: 0.6555 - accuracy: 0.6518
 8/13 [=================>............] - ETA: 58s - loss: 0.6560 - accuracy: 0.6445
 9/13 [===================>..........] - ETA: 46s - loss: 0.6516 - accuracy: 0.6562
10/13 [======================>.......] - ETA: 34s - loss: 0.6492 - accuracy: 0.6656
11/13 [========================>.....] - ETA: 23s - loss: 0.6471 - accuracy: 0.6733
12/13 [==========================>...] - ETA: 11s - loss: 0.6467 - accuracy: 0.6719
13/13 [==============================] - 148s 11s/step - loss: 0.6447 - accuracy: 0.6781
val_acc: 0.68627, best_val_acc: 0.68627, test_acc: 0.72549

Epoch 5/10

 1/13 [=>............................] - ETA: 2:16 - loss: 0.6245 - accuracy: 0.6875
 2/13 [===>..........................] - ETA: 2:04 - loss: 0.6226 - accuracy: 0.7031
 3/13 [=====>........................] - ETA: 1:55 - loss: 0.6086 - accuracy: 0.7188
 4/13 [========>.....................] - ETA: 1:43 - loss: 0.6175 - accuracy: 0.6797
 5/13 [==========>...................] - ETA: 1:32 - loss: 0.6204 - accuracy: 0.6687
 6/13 [============>.................] - ETA: 1:21 - loss: 0.6134 - accuracy: 0.6927
 7/13 [===============>..............] - ETA: 1:09 - loss: 0.6143 - accuracy: 0.6964
 8/13 [=================>............] - ETA: 57s - loss: 0.6070 - accuracy: 0.7109
 9/13 [===================>..........] - ETA: 46s - loss: 0.6115 - accuracy: 0.6979
10/13 [======================>.......] - ETA: 34s - loss: 0.6109 - accuracy: 0.7031
11/13 [========================>.....] - ETA: 23s - loss: 0.6079 - accuracy: 0.7102
12/13 [==========================>...] - ETA: 11s - loss: 0.6123 - accuracy: 0.7005
13/13 [==============================] - 147s 11s/step - loss: 0.6132 - accuracy: 0.6953
val_acc: 0.68627, best_val_acc: 0.68627, test_acc: 0.72549

Epoch 6/10

 1/13 [=>............................] - ETA: 2:12 - loss: 0.6194 - accuracy: 0.6250
 2/13 [===>..........................] - ETA: 2:05 - loss: 0.6052 - accuracy: 0.6719
 3/13 [=====>........................] - ETA: 1:53 - loss: 0.6195 - accuracy: 0.6354
 4/13 [========>.....................] - ETA: 1:42 - loss: 0.6250 - accuracy: 0.6328
 5/13 [==========>...................] - ETA: 1:31 - loss: 0.6239 - accuracy: 0.6438
 6/13 [============>.................] - ETA: 1:20 - loss: 0.6105 - accuracy: 0.6719
 7/13 [===============>..............] - ETA: 1:08 - loss: 0.6027 - accuracy: 0.6830
 8/13 [=================>............] - ETA: 57s - loss: 0.5962 - accuracy: 0.6992
 9/13 [===================>..........] - ETA: 45s - loss: 0.5880 - accuracy: 0.7118
10/13 [======================>.......] - ETA: 34s - loss: 0.5834 - accuracy: 0.7219
11/13 [========================>.....] - ETA: 22s - loss: 0.5799 - accuracy: 0.7216
12/13 [==========================>...] - ETA: 11s - loss: 0.5776 - accuracy: 0.7266
13/13 [==============================] - 146s 11s/step - loss: 0.5759 - accuracy: 0.7273
val_acc: 0.70588, best_val_acc: 0.70588, test_acc: 0.72549

Epoch 7/10

 1/13 [=>............................] - ETA: 2:16 - loss: 0.5550 - accuracy: 0.7188
 2/13 [===>..........................] - ETA: 2:05 - loss: 0.5531 - accuracy: 0.7500
 3/13 [=====>........................] - ETA: 1:55 - loss: 0.5566 - accuracy: 0.7604
 4/13 [========>.....................] - ETA: 1:43 - loss: 0.5491 - accuracy: 0.7656
 5/13 [==========>...................] - ETA: 1:32 - loss: 0.5421 - accuracy: 0.7750
 6/13 [============>.................] - ETA: 1:20 - loss: 0.5498 - accuracy: 0.7656
 7/13 [===============>..............] - ETA: 1:09 - loss: 0.5481 - accuracy: 0.7589
 8/13 [=================>............] - ETA: 57s - loss: 0.5399 - accuracy: 0.7695
 9/13 [===================>..........] - ETA: 46s - loss: 0.5432 - accuracy: 0.7569
10/13 [======================>.......] - ETA: 34s - loss: 0.5431 - accuracy: 0.7594
11/13 [========================>.....] - ETA: 23s - loss: 0.5349 - accuracy: 0.7727
12/13 [==========================>...] - ETA: 11s - loss: 0.5425 - accuracy: 0.7578
13/13 [==============================] - 146s 11s/step - loss: 0.5416 - accuracy: 0.7543
val_acc: 0.74510, best_val_acc: 0.74510, test_acc: 0.70588

Epoch 8/10

 1/13 [=>............................] - ETA: 2:07 - loss: 0.5058 - accuracy: 0.8125
 2/13 [===>..........................] - ETA: 2:00 - loss: 0.5453 - accuracy: 0.7188
 3/13 [=====>........................] - ETA: 1:51 - loss: 0.5370 - accuracy: 0.7188
 4/13 [========>.....................] - ETA: 1:40 - loss: 0.5331 - accuracy: 0.7422
 5/13 [==========>...................] - ETA: 1:29 - loss: 0.5239 - accuracy: 0.7625
 6/13 [============>.................] - ETA: 1:18 - loss: 0.5155 - accuracy: 0.7656
 7/13 [===============>..............] - ETA: 1:07 - loss: 0.5026 - accuracy: 0.7812
 8/13 [=================>............] - ETA: 56s - loss: 0.4982 - accuracy: 0.7930
 9/13 [===================>..........] - ETA: 45s - loss: 0.4999 - accuracy: 0.7951
10/13 [======================>.......] - ETA: 34s - loss: 0.4979 - accuracy: 0.8000
11/13 [========================>.....] - ETA: 22s - loss: 0.4985 - accuracy: 0.8011
12/13 [==========================>...] - ETA: 11s - loss: 0.4992 - accuracy: 0.8021
13/13 [==============================] - 145s 11s/step - loss: 0.4981 - accuracy: 0.8010
val_acc: 0.82353, best_val_acc: 0.82353, test_acc: 0.72549

Epoch 9/10

 1/13 [=>............................] - ETA: 2:17 - loss: 0.4938 - accuracy: 0.8750
 2/13 [===>..........................] - ETA: 2:04 - loss: 0.4755 - accuracy: 0.8438
 3/13 [=====>........................] - ETA: 1:54 - loss: 0.4530 - accuracy: 0.8542
 4/13 [========>.....................] - ETA: 1:43 - loss: 0.4457 - accuracy: 0.8594
 5/13 [==========>...................] - ETA: 1:32 - loss: 0.4385 - accuracy: 0.8562
 6/13 [============>.................] - ETA: 1:19 - loss: 0.4470 - accuracy: 0.8490
 7/13 [===============>..............] - ETA: 1:08 - loss: 0.4479 - accuracy: 0.8571
 8/13 [=================>............] - ETA: 56s - loss: 0.4462 - accuracy: 0.8516
 9/13 [===================>..........] - ETA: 45s - loss: 0.4457 - accuracy: 0.8438
10/13 [======================>.......] - ETA: 34s - loss: 0.4480 - accuracy: 0.8406
11/13 [========================>.....] - ETA: 22s - loss: 0.4472 - accuracy: 0.8381
12/13 [==========================>...] - ETA: 11s - loss: 0.4453 - accuracy: 0.8385
13/13 [==============================] - 144s 11s/step - loss: 0.4461 - accuracy: 0.8378
val_acc: 0.86275, best_val_acc: 0.86275, test_acc: 0.66667

Epoch 10/10

 1/13 [=>............................] - ETA: 2:18 - loss: 0.3911 - accuracy: 0.9688
 2/13 [===>..........................] - ETA: 2:06 - loss: 0.3875 - accuracy: 0.8906
 3/13 [=====>........................] - ETA: 1:55 - loss: 0.3962 - accuracy: 0.8750
 4/13 [========>.....................] - ETA: 1:43 - loss: 0.3903 - accuracy: 0.8828
 5/13 [==========>...................] - ETA: 1:31 - loss: 0.4039 - accuracy: 0.8687
 6/13 [============>.................] - ETA: 1:20 - loss: 0.3997 - accuracy: 0.8750
 7/13 [===============>..............] - ETA: 1:08 - loss: 0.4021 - accuracy: 0.8661
 8/13 [=================>............] - ETA: 56s - loss: 0.3999 - accuracy: 0.8672
 9/13 [===================>..........] - ETA: 45s - loss: 0.3995 - accuracy: 0.8715
10/13 [======================>.......] - ETA: 33s - loss: 0.4032 - accuracy: 0.8625
11/13 [========================>.....] - ETA: 22s - loss: 0.4034 - accuracy: 0.8608
12/13 [==========================>...] - ETA: 11s - loss: 0.3958 - accuracy: 0.8672
13/13 [==============================] - 144s 11s/step - loss: 0.3898 - accuracy: 0.8722
val_acc: 0.84314, best_val_acc: 0.86275, test_acc: 0.72549

final test acc: 0.72549
